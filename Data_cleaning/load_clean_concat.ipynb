{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b747c15",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "689fda5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from scipy import \n",
    "#from sklearn import\n",
    "from datetime import datetime\n",
    "import re\n",
    "# pd.set_option(\"display.max_rows\", 100)\n",
    "# from IPython.core.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1bfebb",
   "metadata": {},
   "source": [
    "### General variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e33594ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../../../Data/'\n",
    "print_text_result = False\n",
    "raw_data_names = ['pit1_data-2022', 'pit2_data-2022', 'pit3_data-2022', 'pit4_data-2022',\n",
    "                  'pit1_data-2023', 'pit2_data-2023', 'pit3_data-2023', 'pit4_data-2023']\n",
    "clean_data_names = ['VII_PIT1_2022', 'VII_PIT2_2022', 'VII_PIT3_2022', 'VII_PIT4_2022']\n",
    "df_pairs = [('pit1_data-2022', 'VII_PIT1_2022'), ('pit2_data-2022', 'VII_PIT2_2022'), ('pit3_data-2022', 'VII_PIT3_2022'), ('pit4_data-2022', 'VII_PIT4_2022'),\n",
    "            ('pit1_data-2023', None), ('pit2_data-2023', None), ('pit3_data-2023', None), ('pit4_data-2023', None)]\n",
    "col_types = ['int64', 'int64', 'int64', 'int64', 'int64', 'int64', 'int64', 'float64', 'int64', 'int64',\n",
    "             'float64', 'int64', 'int64', 'float64', 'int64', 'int64', 'float64', 'int64', 'int64', 'float64',\n",
    "             'int64', 'float64', 'float64', 'float64', 'float64', 'int64', 'float64', 'float64', 'float64', 'float64',\n",
    "             'float64', 'float64', 'float64', 'float64', 'float64', 'int64', 'bool', 'bool', 'int64', 'float64',\n",
    "             'float64', 'float64', 'float64', 'float64', 'float64', 'float64', 'bool']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f62b14e",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a471267",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_result(header: str, init_count: int, new_count: int):\n",
    "    print(header)\n",
    "    print(f'\\tinit row cnt: {init_count}')\n",
    "    print(f'\\t# of rows deleted: {init_count - new_count}')\n",
    "    print(f'\\tresult row count : {new_count}')\n",
    "\n",
    "def remove_pit_suffix(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove suffix '_pit<number>' from header\n",
    "    \"\"\"\n",
    "    re_match = re.search(r'_pit\\d+$', name)\n",
    "    if re_match:\n",
    "        name = name[:re_match.start()]\n",
    "    return name\n",
    "\n",
    "def filter_dates(df: pd.DataFrame, file_name: str) -> int:\n",
    "    init_row_cnt = len(df)\n",
    "    start_date_2023 = datetime(2023, 1,1, 0, 0, 0)\n",
    "\n",
    "    if '2022' in file_name:\n",
    "        df.drop(df[df['TIMESTAMP'] >= start_date_2023].index, inplace=True)\n",
    "    else:\n",
    "        df.drop(df[df['TIMESTAMP'] < start_date_2023].index, inplace=True)\n",
    "\n",
    "    if print_text_result: print_result('FILTERING DATES BY YEAR:', init_row_cnt, len(df))\n",
    "\n",
    "    return (init_row_cnt - len(df))\n",
    "\n",
    "def filter_duplicate_date(df: pd.DataFrame) -> int:\n",
    "    init_row_cnt = len(df)\n",
    "    \n",
    "    df.drop_duplicates(subset='TIMESTAMP', inplace=True)\n",
    "\n",
    "    if print_text_result: print_result('FILTERING DUPLICATE DATES:', init_row_cnt, len(df))\n",
    "\n",
    "    return (init_row_cnt - len(df))\n",
    "\n",
    "def filter_missing_values(df: pd.DataFrame, file_name: str, remove_empy=True) -> int:\n",
    "    init_row_cnt = df.shape[0]\n",
    "    if remove_empy and 'VII' not in file_name:\n",
    "        df.dropna(inplace=True)\n",
    "    # TODO else:\n",
    "        # filter cleaned data\n",
    "        # fill missing data\n",
    "\n",
    "    if print_text_result: print_result('FILTERING MISSING VALUES:', init_row_cnt, len(df))\n",
    "\n",
    "    return (init_row_cnt - len(df))\n",
    "\n",
    "def filter_df(df: pd.DataFrame, file_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Filters the given DataFrame by removing specific rows\n",
    "    \"\"\"\n",
    "    diff_dict = dict()\n",
    "    diff_dict['dates_removed'] = filter_dates(df, file_name)\n",
    "    diff_dict['duplicates_removed'] = filter_duplicate_date(df)\n",
    "    diff_dict['missing_data_removed'] = filter_missing_values(df, file_name)\n",
    "    return diff_dict\n",
    "\n",
    "def fix_types(df: pd.DataFrame, file_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fix data types from given DataFrame\n",
    "    \"\"\"\n",
    "    if 'VII' in file_name:\n",
    "        return df\n",
    "    for col_type, col_name in zip(col_types, list(df.columns.array)[1:]):\n",
    "        if col_type == 'int64':\n",
    "            df[col_name] = df[col_name].astype('float64').astype('int64')\n",
    "        elif col_type == 'float64':\n",
    "            df[col_name] = df[col_name].astype('float64')\n",
    "        else:\n",
    "            df[col_name] = df[col_name].astype('bool')\n",
    "    return df\n",
    "\n",
    "def add_pit_column(df: pd.DataFrame, file_name: str) -> pd.DataFrame:\n",
    "    if 'VII' in file_name:\n",
    "        return df\n",
    "    pit_n = file_name[3]\n",
    "    df['pit_number'] = int(pit_n)\n",
    "    return df\n",
    "\n",
    "def merge_raw_cleaned(raw_dfs, clean_dfs, df_pairs: list[(str, str)] = df_pairs):\n",
    "    merged_dfs = []\n",
    "    for pair in df_pairs:\n",
    "        raw = raw_dfs[pair[0]]\n",
    "        if pair[1] is None:\n",
    "            for x in range(1,6):\n",
    "                raw[f'Redox_error_flag({x})'] = False\n",
    "            raw['Redox_error_flag_available'] = False\n",
    "            merged_dfs.append(raw)\n",
    "        else:\n",
    "            cleaned = clean_dfs[pair[1]]\n",
    "            for x in range(1,6):\n",
    "                cleaned[f'Redox_error_flag({x})'] = (cleaned['Redox_error_flag'] == True) & (cleaned[f'Redox_Avg({x})'].isna())\n",
    "            cleaned = cleaned.drop(['Redox_error_flag'], axis=1)\n",
    "            merged = raw.merge(\n",
    "                cleaned[['TIMESTAMP', 'Redox_error_flag(1)', 'Redox_error_flag(2)', 'Redox_error_flag(3)', 'Redox_error_flag(4)', 'Redox_error_flag(5)']],\n",
    "                how='left',\n",
    "                left_on='TIMESTAMP',\n",
    "                right_on='TIMESTAMP'\n",
    "            )\n",
    "            merged['Redox_error_flag_available'] = True\n",
    "            merged_dfs.append(merged)\n",
    "    return merged_dfs\n",
    "\n",
    "def add_redox_log_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for x in range(1,6):\n",
    "        df[f'neg_log({x})'] = df[f'Redox_Avg({x})'] < 0\n",
    "        df[f'log_redox({x})'] = np.log(np.abs(df[f'Redox_Avg({x})']))\n",
    "    return df\n",
    "\n",
    "def load_data(file_names: list[str], data_folder: str) -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load data from given file names\n",
    "    :param file_names: list of file names\n",
    "    :param data_folder: folder name where data is located\n",
    "    :return: dictionary of DataFrames\n",
    "    \"\"\"\n",
    "    dfs = dict()\n",
    "    report_df = pd.DataFrame()\n",
    "\n",
    "    for file_name in file_names:\n",
    "        df = pd.read_csv(data_folder+file_name+'.csv', parse_dates=['TIMESTAMP'])\n",
    "        df.rename(mapper=remove_pit_suffix, axis='columns', inplace=True)\n",
    "            \n",
    "        if print_text_result: print(f'===== {file_name} =====')\n",
    "\n",
    "        stats = filter_df(df, file_name)\n",
    "        df = fix_types(df, file_name)\n",
    "        df = add_pit_column(df, file_name)\n",
    "        df = add_redox_log_cols(df)\n",
    "        report_df = pd.concat([report_df, pd.DataFrame(stats, index=[file_name])])\n",
    "        dfs[file_name] = df\n",
    "\n",
    "        if print_text_result: print('\\n')\n",
    "\n",
    "    report_df = report_df.assign(Total = lambda x: (x.sum(axis=1)))\n",
    "    print(report_df)\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1215119e",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "425335a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60324/1407515731.py:1: DtypeWarning: Columns (34,37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = load_data(raw_data_names, data_folder)\n",
      "/usr/lib/python3/dist-packages/pandas/core/arraylike.py:364: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/lib/python3/dist-packages/pandas/core/arraylike.py:364: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_60324/1407515731.py:1: DtypeWarning: Columns (34) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = load_data(raw_data_names, data_folder)\n",
      "/tmp/ipykernel_60324/1407515731.py:1: DtypeWarning: Columns (37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = load_data(raw_data_names, data_folder)\n",
      "/tmp/ipykernel_60324/1407515731.py:1: DtypeWarning: Columns (7,8,9,34,37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = load_data(raw_data_names, data_folder)\n",
      "/tmp/ipykernel_60324/1407515731.py:1: DtypeWarning: Columns (19,20,21,30,31,34,37,38) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = load_data(raw_data_names, data_folder)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                dates_removed  duplicates_removed  missing_data_removed  Total\n",
      "pit1_data-2022              1                  12                   267    280\n",
      "pit2_data-2022              1                  24                  4348   4373\n",
      "pit3_data-2022              1                  12                   167    180\n",
      "pit4_data-2022              1                  12                   125    138\n",
      "pit1_data-2023            287                  15                   279    581\n",
      "pit2_data-2023           3248               25552                  7215  36015\n",
      "pit3_data-2023            287                  88                   279    654\n",
      "pit4_data-2023            287                 196                  1143   1626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60324/1407515731.py:2: DtypeWarning: Columns (37,38,47) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  clean_data = load_data(clean_data_names, data_folder)\n",
      "/usr/lib/python3/dist-packages/pandas/core/arraylike.py:364: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/usr/lib/python3/dist-packages/pandas/core/arraylike.py:364: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_60324/1407515731.py:2: DtypeWarning: Columns (47) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  clean_data = load_data(clean_data_names, data_folder)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               dates_removed  duplicates_removed  missing_data_removed  Total\n",
      "VII_PIT1_2022              1                 192                     0    193\n",
      "VII_PIT2_2022              1                  24                     0     25\n",
      "VII_PIT3_2022              1                  12                     0     13\n",
      "VII_PIT4_2022              1                  12                     0     13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60324/1407515731.py:2: DtypeWarning: Columns (38) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  clean_data = load_data(clean_data_names, data_folder)\n"
     ]
    }
   ],
   "source": [
    "raw_data = load_data(raw_data_names, data_folder)\n",
    "clean_data = load_data(clean_data_names, data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4279fe4a",
   "metadata": {},
   "source": [
    "### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4598ba95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>RECORD</th>\n",
       "      <th>Redox_Avg(1)</th>\n",
       "      <th>Redox_Avg(2)</th>\n",
       "      <th>Redox_Avg(3)</th>\n",
       "      <th>Redox_Avg(4)</th>\n",
       "      <th>Redox_Avg(5)</th>\n",
       "      <th>CCVWC_Avg(1)</th>\n",
       "      <th>Temp_T12_Avg(1)</th>\n",
       "      <th>EC_Avg(1)</th>\n",
       "      <th>...</th>\n",
       "      <th>WC2</th>\n",
       "      <th>WC3</th>\n",
       "      <th>WC4</th>\n",
       "      <th>WC5</th>\n",
       "      <th>pit_number</th>\n",
       "      <th>log_redox(1)</th>\n",
       "      <th>log_redox(2)</th>\n",
       "      <th>log_redox(3)</th>\n",
       "      <th>log_redox(4)</th>\n",
       "      <th>log_redox(5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-12 09:00:00</td>\n",
       "      <td>31570</td>\n",
       "      <td>138</td>\n",
       "      <td>301</td>\n",
       "      <td>176</td>\n",
       "      <td>84</td>\n",
       "      <td>61</td>\n",
       "      <td>2404</td>\n",
       "      <td>0.2</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393623</td>\n",
       "      <td>0.435904</td>\n",
       "      <td>0.458790</td>\n",
       "      <td>0.504951</td>\n",
       "      <td>1</td>\n",
       "      <td>4.927254</td>\n",
       "      <td>5.707110</td>\n",
       "      <td>5.170484</td>\n",
       "      <td>4.430817</td>\n",
       "      <td>4.110874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-12 09:05:00</td>\n",
       "      <td>31571</td>\n",
       "      <td>138</td>\n",
       "      <td>301</td>\n",
       "      <td>176</td>\n",
       "      <td>84</td>\n",
       "      <td>61</td>\n",
       "      <td>2405</td>\n",
       "      <td>0.2</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393623</td>\n",
       "      <td>0.435904</td>\n",
       "      <td>0.458402</td>\n",
       "      <td>0.504563</td>\n",
       "      <td>1</td>\n",
       "      <td>4.927254</td>\n",
       "      <td>5.707110</td>\n",
       "      <td>5.170484</td>\n",
       "      <td>4.430817</td>\n",
       "      <td>4.110874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-12 09:10:00</td>\n",
       "      <td>31572</td>\n",
       "      <td>138</td>\n",
       "      <td>301</td>\n",
       "      <td>176</td>\n",
       "      <td>84</td>\n",
       "      <td>61</td>\n",
       "      <td>2405</td>\n",
       "      <td>0.2</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393623</td>\n",
       "      <td>0.435904</td>\n",
       "      <td>0.458402</td>\n",
       "      <td>0.504951</td>\n",
       "      <td>1</td>\n",
       "      <td>4.927254</td>\n",
       "      <td>5.707110</td>\n",
       "      <td>5.170484</td>\n",
       "      <td>4.430817</td>\n",
       "      <td>4.110874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-12 09:15:00</td>\n",
       "      <td>31573</td>\n",
       "      <td>138</td>\n",
       "      <td>302</td>\n",
       "      <td>175</td>\n",
       "      <td>84</td>\n",
       "      <td>61</td>\n",
       "      <td>2405</td>\n",
       "      <td>0.2</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394011</td>\n",
       "      <td>0.435904</td>\n",
       "      <td>0.458790</td>\n",
       "      <td>0.504951</td>\n",
       "      <td>1</td>\n",
       "      <td>4.927254</td>\n",
       "      <td>5.710427</td>\n",
       "      <td>5.164786</td>\n",
       "      <td>4.430817</td>\n",
       "      <td>4.110874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-12 09:20:00</td>\n",
       "      <td>31574</td>\n",
       "      <td>138</td>\n",
       "      <td>301</td>\n",
       "      <td>175</td>\n",
       "      <td>84</td>\n",
       "      <td>61</td>\n",
       "      <td>2405</td>\n",
       "      <td>0.2</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393623</td>\n",
       "      <td>0.435904</td>\n",
       "      <td>0.458790</td>\n",
       "      <td>0.504951</td>\n",
       "      <td>1</td>\n",
       "      <td>4.927254</td>\n",
       "      <td>5.707110</td>\n",
       "      <td>5.164786</td>\n",
       "      <td>4.430817</td>\n",
       "      <td>4.110874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            TIMESTAMP  RECORD  Redox_Avg(1)  Redox_Avg(2)  Redox_Avg(3)  \\\n",
       "0 2022-04-12 09:00:00   31570           138           301           176   \n",
       "1 2022-04-12 09:05:00   31571           138           301           176   \n",
       "2 2022-04-12 09:10:00   31572           138           301           176   \n",
       "3 2022-04-12 09:15:00   31573           138           302           175   \n",
       "4 2022-04-12 09:20:00   31574           138           301           175   \n",
       "\n",
       "   Redox_Avg(4)  Redox_Avg(5)  CCVWC_Avg(1)  Temp_T12_Avg(1)  EC_Avg(1)  ...  \\\n",
       "0            84            61          2404              0.2         79  ...   \n",
       "1            84            61          2405              0.2         79  ...   \n",
       "2            84            61          2405              0.2         80  ...   \n",
       "3            84            61          2405              0.2         80  ...   \n",
       "4            84            61          2405              0.2         80  ...   \n",
       "\n",
       "        WC2       WC3       WC4       WC5  pit_number  log_redox(1)  \\\n",
       "0  0.393623  0.435904  0.458790  0.504951           1      4.927254   \n",
       "1  0.393623  0.435904  0.458402  0.504563           1      4.927254   \n",
       "2  0.393623  0.435904  0.458402  0.504951           1      4.927254   \n",
       "3  0.394011  0.435904  0.458790  0.504951           1      4.927254   \n",
       "4  0.393623  0.435904  0.458790  0.504951           1      4.927254   \n",
       "\n",
       "   log_redox(2)  log_redox(3)  log_redox(4)  log_redox(5)  \n",
       "0      5.707110      5.170484      4.430817      4.110874  \n",
       "1      5.707110      5.170484      4.430817      4.110874  \n",
       "2      5.707110      5.170484      4.430817      4.110874  \n",
       "3      5.710427      5.164786      4.430817      4.110874  \n",
       "4      5.707110      5.164786      4.430817      4.110874  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['pit1_data-2022'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262bc7dd",
   "metadata": {},
   "source": [
    "### Dtypes in each dataframe\n",
    "\n",
    "    NOTE: Cleaned data dtypes not changed yet. Need to think how to deal with missing values for column which should be converted to int64 from original float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72a7a6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t1\t\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\t13\t14\t15\t16\t17\t18\t19\t20\t21\t22\t23\t24\t25\t26\t27\t28\t29\t30\t31\t32\t33\t34\t35\t36\t37\t38\t39\t40\t41\t42\t43\t44\t45\t46\t47\t48\n",
      "pit1_data-2022\t1\tdatetime64[ns]\tint64\tint64\tint64\tint64\tint64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tbool\tbool\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\n",
      "pit2_data-2022\t2\tdatetime64[ns]\tint64\tint64\tint64\tint64\tint64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tbool\tbool\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\n",
      "pit3_data-2022\t3\tdatetime64[ns]\tint64\tint64\tint64\tint64\tint64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tbool\tbool\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\n",
      "pit4_data-2022\t4\tdatetime64[ns]\tint64\tint64\tint64\tint64\tint64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tbool\tbool\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\n",
      "pit1_data-2023\t5\tdatetime64[ns]\tint64\tint64\tint64\tint64\tint64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tbool\tbool\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\n",
      "pit2_data-2023\t6\tdatetime64[ns]\tint64\tint64\tint64\tint64\tint64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tbool\tbool\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\n",
      "pit3_data-2023\t7\tdatetime64[ns]\tint64\tint64\tint64\tint64\tint64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tbool\tbool\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\n",
      "pit4_data-2023\t8\tdatetime64[ns]\tint64\tint64\tint64\tint64\tint64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tbool\tbool\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\n",
      "VII_PIT1_2022\t9\tdatetime64[ns]\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tobject\tobject\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tobject\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\n",
      "VII_PIT2_2022\t10\tdatetime64[ns]\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tbool\tbool\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tobject\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\n",
      "VII_PIT3_2022\t11\tint64\tdatetime64[ns]\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tobject\tbool\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tbool\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\n",
      "VII_PIT4_2022\t12\tdatetime64[ns]\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tbool\tbool\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tobject\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "print('\\t\\t\\t'+'1\\t\\t'+'\\t'.join(str(a) for a in [*range(2,49)]))\n",
    "for t1 in zip([*raw_data.items(), *clean_data.items()]):\n",
    "    print(f'{t1[0][0]}\\t{i}\\t'+'\\t'.join(str(x) for x in t1[0][1].dtypes.array))\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d37fd",
   "metadata": {},
   "source": [
    "### Remove timestamps from raw data that do not match in cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d14cb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking pit1_data-2022 vs VII_PIT1_2022\n",
      "\t Rows removed 0\n",
      "Checking pit2_data-2022 vs VII_PIT2_2022\n",
      "\t Rows removed 0\n",
      "Checking pit3_data-2022 vs VII_PIT3_2022\n",
      "\t Rows removed 0\n",
      "Checking pit4_data-2022 vs VII_PIT4_2022\n",
      "\t Rows removed 1916\n"
     ]
    }
   ],
   "source": [
    "for pair in df_pairs:\n",
    "    raw_data_name, clean_data_name = pair[0], pair[1]\n",
    "    if clean_data_name:\n",
    "        print(f'Checking {raw_data_name} vs {clean_data_name}')\n",
    "        clean_timestamps = clean_data[clean_data_name]['TIMESTAMP'].to_numpy()\n",
    "        prev_row_count = len(raw_data[raw_data_name])\n",
    "        raw_data[raw_data_name] = raw_data[raw_data_name].loc[raw_data[raw_data_name]['TIMESTAMP'].isin(clean_timestamps) == True]\n",
    "        print(f'\\t Rows removed {prev_row_count-len(raw_data[raw_data_name])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30da575",
   "metadata": {},
   "source": [
    "### Add redox error flag columns and merge them with raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "83d5df44",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dfs = merge_raw_cleaned(raw_data, clean_data, df_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89496cb7",
   "metadata": {},
   "source": [
    "### Combine all raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "41b712dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.DataFrame()\n",
    "for df in merged_dfs:\n",
    "    raw = pd.concat([raw, df])\n",
    "\n",
    "training_folder_path = f'{data_folder}/Training/'\n",
    "raw.to_csv(f'{training_folder_path}Raw_training_data_full.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
