{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b747c15",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "689fda5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "#from scipy import \n",
    "#from sklearn import\n",
    "from datetime import datetime\n",
    "import re\n",
    "# pd.set_option(\"display.max_rows\", 100)\n",
    "# from IPython.core.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1bfebb",
   "metadata": {},
   "source": [
    "### General variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e33594ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../Data/'\n",
    "print_text_result = False\n",
    "raw_data_names = ['pit1_data-2022', 'pit2_data-2022', 'pit3_data-2022', 'pit4_data-2022',\n",
    "                  'pit1_data-2023', 'pit2_data-2023', 'pit3_data-2023', 'pit4_data-2023']\n",
    "clean_data_names = ['VII_PIT1_2022', 'VII_PIT2_2022', 'VII_PIT3_2022', 'VII_PIT4_2022']\n",
    "col_types = ['int64', 'int64', 'int64', 'int64', 'int64', 'int64', 'int64', 'float64', 'int64', 'int64',\n",
    "             'float64', 'int64', 'int64', 'float64', 'int64', 'int64', 'float64', 'int64', 'int64', 'float64',\n",
    "             'int64', 'float64', 'float64', 'float64', 'float64', 'int64', 'float64', 'float64', 'float64', 'float64',\n",
    "             'float64', 'float64', 'float64', 'float64', 'float64', 'int64', 'bool', 'bool', 'int64', 'float64',\n",
    "             'float64', 'float64', 'float64', 'float64', 'float64', 'float64', 'bool']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f62b14e",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a471267",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_result(header: str, init_count: int, new_count: int):\n",
    "    print(header)\n",
    "    print(f'\\tinit row cnt: {init_count}')\n",
    "    print(f'\\t# of rows deleted: {init_count - new_count}')\n",
    "    print(f'\\tresult row count : {new_count}')\n",
    "\n",
    "def remove_pit_suffix(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove suffix '_pit<number>' from header\n",
    "    \"\"\"\n",
    "    re_match = re.search(r'_pit\\d+$', name)\n",
    "    if re_match:\n",
    "        name = name[:re_match.start()]\n",
    "    return name\n",
    "\n",
    "def filter_dates(df: pd.DataFrame, file_name: str) -> int:\n",
    "    init_row_cnt = len(df)\n",
    "    start_date_2023 = datetime(2023, 1,1, 0, 0, 0)\n",
    "\n",
    "    if '2022' in file_name:\n",
    "        df.drop(df[df['TIMESTAMP'] >= start_date_2023].index, inplace=True)\n",
    "    else:\n",
    "        df.drop(df[df['TIMESTAMP'] < start_date_2023].index, inplace=True)\n",
    "\n",
    "    if print_text_result: print_result('FILTERING DATES BY YEAR:', init_row_cnt, len(df))\n",
    "\n",
    "    return (init_row_cnt - len(df))\n",
    "\n",
    "def filter_duplicate_date(df: pd.DataFrame) -> int:\n",
    "    init_row_cnt = len(df)\n",
    "    \n",
    "    df.drop_duplicates(subset='TIMESTAMP', inplace=True)\n",
    "\n",
    "    if print_text_result: print_result('FILTERING DUPLICATE DATES:', init_row_cnt, len(df))\n",
    "\n",
    "    return (init_row_cnt - len(df))\n",
    "\n",
    "def filter_missing_values(df: pd.DataFrame, file_name: str, remove_empy=True) -> int:\n",
    "    init_row_cnt = df.shape[0]\n",
    "    if remove_empy and 'VII' not in file_name:\n",
    "        df.dropna(inplace=True)\n",
    "    # TODO else:\n",
    "        # filter cleaned data\n",
    "        # fill missing data\n",
    "\n",
    "    if print_text_result: print_result('FILTERING MISSING VALUES:', init_row_cnt, len(df))\n",
    "\n",
    "    return (init_row_cnt - len(df))\n",
    "\n",
    "def filter_df(df: pd.DataFrame, file_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Filters the given DataFrame by removing specific rows\n",
    "    \"\"\"\n",
    "    diff_dict = dict()\n",
    "    diff_dict['dates_removed'] = filter_dates(df, file_name)\n",
    "    diff_dict['duplicates_removed'] = filter_duplicate_date(df)\n",
    "    diff_dict['missing_data_removed'] = filter_missing_values(df, file_name)\n",
    "    return diff_dict\n",
    "\n",
    "def fix_types(df: pd.DataFrame, file_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fix data types from given DataFrame\n",
    "    \"\"\"\n",
    "    if 'VII' in file_name:\n",
    "        return df\n",
    "    for col_type, col_name in zip(col_types, list(df.columns.array)[1:]):\n",
    "        if col_type == 'int64':\n",
    "            df[col_name] = df[col_name].astype('float64').astype('int64')\n",
    "        elif col_type == 'float64':\n",
    "            df[col_name] = df[col_name].astype('float64')\n",
    "        else:\n",
    "            df[col_name] = df[col_name].astype('bool')\n",
    "    return df\n",
    "\n",
    "def load_data(file_names: list[str], data_folder: str) -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load data from given file names\n",
    "    :param file_names: list of file names\n",
    "    :param data_folder: folder name where data is located\n",
    "    :return: dictionary of DataFrames\n",
    "    \"\"\"\n",
    "    dfs = dict()\n",
    "    report_df = pd.DataFrame()\n",
    "\n",
    "    for file_name in file_names:\n",
    "        df = pd.read_csv(data_folder+file_name+'.csv', parse_dates=['TIMESTAMP'])\n",
    "        df.rename(mapper=remove_pit_suffix, axis='columns', inplace=True)\n",
    "            \n",
    "        if print_text_result: print(f'===== {file_name} =====')\n",
    "\n",
    "        stats = filter_df(df, file_name)\n",
    "        # TODO add log scale to redox and error flag for each redox depth\n",
    "        df = fix_types(df, file_name)\n",
    "        report_df = pd.concat([report_df, pd.DataFrame(stats, index=[file_name])])\n",
    "        dfs[file_name] = df\n",
    "\n",
    "        if print_text_result: print('\\n')\n",
    "\n",
    "    report_df = report_df.assign(Total = lambda x: (x.sum(axis=1)))\n",
    "    print(report_df)\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1215119e",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "425335a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21713/1407515731.py:1: DtypeWarning: Columns (34,37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = load_data(raw_data_names, data_folder)\n",
      "/tmp/ipykernel_21713/1407515731.py:1: DtypeWarning: Columns (34) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = load_data(raw_data_names, data_folder)\n",
      "/tmp/ipykernel_21713/1407515731.py:1: DtypeWarning: Columns (37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = load_data(raw_data_names, data_folder)\n",
      "/tmp/ipykernel_21713/1407515731.py:1: DtypeWarning: Columns (7,8,9,34,37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = load_data(raw_data_names, data_folder)\n",
      "/tmp/ipykernel_21713/1407515731.py:1: DtypeWarning: Columns (19,20,21,30,31,34,37,38) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = load_data(raw_data_names, data_folder)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                dates_removed  duplicates_removed  missing_data_removed  Total\n",
      "pit1_data-2022              1                  12                   267    280\n",
      "pit2_data-2022              1                  24                  4348   4373\n",
      "pit3_data-2022              1                  12                   167    180\n",
      "pit4_data-2022              1                  12                   125    138\n",
      "pit1_data-2023            287                  15                   279    581\n",
      "pit2_data-2023           3248               25552                  7215  36015\n",
      "pit3_data-2023            287                  88                   279    654\n",
      "pit4_data-2023            287                 196                  1143   1626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21713/1407515731.py:2: DtypeWarning: Columns (37,38,47) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  clean_data = load_data(clean_data_names, data_folder)\n",
      "/tmp/ipykernel_21713/1407515731.py:2: DtypeWarning: Columns (47) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  clean_data = load_data(clean_data_names, data_folder)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               dates_removed  duplicates_removed  missing_data_removed  Total\n",
      "VII_PIT1_2022              1                 192                     0    193\n",
      "VII_PIT2_2022              1                  24                     0     25\n",
      "VII_PIT3_2022              1                  12                     0     13\n",
      "VII_PIT4_2022              1                  12                     0     13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21713/1407515731.py:2: DtypeWarning: Columns (37,47) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  clean_data = load_data(clean_data_names, data_folder)\n"
     ]
    }
   ],
   "source": [
    "raw_data = load_data(raw_data_names, data_folder)\n",
    "clean_data = load_data(clean_data_names, data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4279fe4a",
   "metadata": {},
   "source": [
    "### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4598ba95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>RECORD</th>\n",
       "      <th>Redox_Avg(1)</th>\n",
       "      <th>Redox_Avg(2)</th>\n",
       "      <th>Redox_Avg(3)</th>\n",
       "      <th>Redox_Avg(4)</th>\n",
       "      <th>Redox_Avg(5)</th>\n",
       "      <th>CCVWC_Avg(1)</th>\n",
       "      <th>Temp_T12_Avg(1)</th>\n",
       "      <th>EC_Avg(1)</th>\n",
       "      <th>...</th>\n",
       "      <th>shfp_wrnng_flg</th>\n",
       "      <th>btt_wrnng_flg</th>\n",
       "      <th>BatterymV_Min</th>\n",
       "      <th>BattV_Min</th>\n",
       "      <th>PTemp_C_Avg</th>\n",
       "      <th>WC1</th>\n",
       "      <th>WC2</th>\n",
       "      <th>WC3</th>\n",
       "      <th>WC4</th>\n",
       "      <th>WC5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-12 09:00:00</td>\n",
       "      <td>31570</td>\n",
       "      <td>138</td>\n",
       "      <td>301</td>\n",
       "      <td>176</td>\n",
       "      <td>84</td>\n",
       "      <td>61</td>\n",
       "      <td>2404</td>\n",
       "      <td>0.2</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1267</td>\n",
       "      <td>12.77</td>\n",
       "      <td>9.05</td>\n",
       "      <td>0.236912</td>\n",
       "      <td>0.393623</td>\n",
       "      <td>0.435904</td>\n",
       "      <td>0.458790</td>\n",
       "      <td>0.504951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-12 09:05:00</td>\n",
       "      <td>31571</td>\n",
       "      <td>138</td>\n",
       "      <td>301</td>\n",
       "      <td>176</td>\n",
       "      <td>84</td>\n",
       "      <td>61</td>\n",
       "      <td>2405</td>\n",
       "      <td>0.2</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1267</td>\n",
       "      <td>12.77</td>\n",
       "      <td>9.38</td>\n",
       "      <td>0.237299</td>\n",
       "      <td>0.393623</td>\n",
       "      <td>0.435904</td>\n",
       "      <td>0.458402</td>\n",
       "      <td>0.504563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-12 09:10:00</td>\n",
       "      <td>31572</td>\n",
       "      <td>138</td>\n",
       "      <td>301</td>\n",
       "      <td>176</td>\n",
       "      <td>84</td>\n",
       "      <td>61</td>\n",
       "      <td>2405</td>\n",
       "      <td>0.2</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1267</td>\n",
       "      <td>12.77</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.237299</td>\n",
       "      <td>0.393623</td>\n",
       "      <td>0.435904</td>\n",
       "      <td>0.458402</td>\n",
       "      <td>0.504951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-12 09:15:00</td>\n",
       "      <td>31573</td>\n",
       "      <td>138</td>\n",
       "      <td>302</td>\n",
       "      <td>175</td>\n",
       "      <td>84</td>\n",
       "      <td>61</td>\n",
       "      <td>2405</td>\n",
       "      <td>0.2</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1267</td>\n",
       "      <td>12.77</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.237299</td>\n",
       "      <td>0.394011</td>\n",
       "      <td>0.435904</td>\n",
       "      <td>0.458790</td>\n",
       "      <td>0.504951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-12 09:20:00</td>\n",
       "      <td>31574</td>\n",
       "      <td>138</td>\n",
       "      <td>301</td>\n",
       "      <td>175</td>\n",
       "      <td>84</td>\n",
       "      <td>61</td>\n",
       "      <td>2405</td>\n",
       "      <td>0.2</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1267</td>\n",
       "      <td>12.77</td>\n",
       "      <td>10.23</td>\n",
       "      <td>0.237299</td>\n",
       "      <td>0.393623</td>\n",
       "      <td>0.435904</td>\n",
       "      <td>0.458790</td>\n",
       "      <td>0.504951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            TIMESTAMP  RECORD  Redox_Avg(1)  Redox_Avg(2)  Redox_Avg(3)  \\\n",
       "0 2022-04-12 09:00:00   31570           138           301           176   \n",
       "1 2022-04-12 09:05:00   31571           138           301           176   \n",
       "2 2022-04-12 09:10:00   31572           138           301           176   \n",
       "3 2022-04-12 09:15:00   31573           138           302           175   \n",
       "4 2022-04-12 09:20:00   31574           138           301           175   \n",
       "\n",
       "   Redox_Avg(4)  Redox_Avg(5)  CCVWC_Avg(1)  Temp_T12_Avg(1)  EC_Avg(1)  ...  \\\n",
       "0            84            61          2404              0.2         79  ...   \n",
       "1            84            61          2405              0.2         79  ...   \n",
       "2            84            61          2405              0.2         80  ...   \n",
       "3            84            61          2405              0.2         80  ...   \n",
       "4            84            61          2405              0.2         80  ...   \n",
       "\n",
       "   shfp_wrnng_flg  btt_wrnng_flg  BatterymV_Min  BattV_Min  PTemp_C_Avg  \\\n",
       "0            True          False           1267      12.77         9.05   \n",
       "1            True          False           1267      12.77         9.38   \n",
       "2            True          False           1267      12.77         9.69   \n",
       "3            True          False           1267      12.77        10.00   \n",
       "4            True          False           1267      12.77        10.23   \n",
       "\n",
       "        WC1       WC2       WC3       WC4       WC5  \n",
       "0  0.236912  0.393623  0.435904  0.458790  0.504951  \n",
       "1  0.237299  0.393623  0.435904  0.458402  0.504563  \n",
       "2  0.237299  0.393623  0.435904  0.458402  0.504951  \n",
       "3  0.237299  0.394011  0.435904  0.458790  0.504951  \n",
       "4  0.237299  0.393623  0.435904  0.458790  0.504951  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['pit1_data-2022'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262bc7dd",
   "metadata": {},
   "source": [
    "### Dtypes in each dataframe\n",
    "\n",
    "    NOTE: Cleaned data dtypes not changed yet. Need to think how to deal with missing values for column which should be converted to int64 from original float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72a7a6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t1\t\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\t13\t14\t15\t16\t17\t18\t19\t20\t21\t22\t23\t24\t25\t26\t27\t28\t29\t30\t31\t32\t33\t34\t35\t36\t37\t38\t39\t40\t41\t42\t43\t44\t45\t46\t47\t48\n",
      "pit1_data-2022\t1\tdatetime64[ns]\tint64\tint64\tint64\tint64\tint64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tbool\tbool\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\n",
      "pit2_data-2022\t2\tdatetime64[ns]\tint64\tint64\tint64\tint64\tint64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tbool\tbool\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\n",
      "pit3_data-2022\t3\tdatetime64[ns]\tint64\tint64\tint64\tint64\tint64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tbool\tbool\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\n",
      "pit4_data-2022\t4\tdatetime64[ns]\tint64\tint64\tint64\tint64\tint64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tbool\tbool\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\n",
      "pit1_data-2023\t5\tdatetime64[ns]\tint64\tint64\tint64\tint64\tint64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tbool\tbool\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\n",
      "pit2_data-2023\t6\tdatetime64[ns]\tint64\tint64\tint64\tint64\tint64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tbool\tbool\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\n",
      "pit3_data-2023\t7\tdatetime64[ns]\tint64\tint64\tint64\tint64\tint64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tbool\tbool\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\n",
      "pit4_data-2023\t8\tdatetime64[ns]\tint64\tint64\tint64\tint64\tint64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tint64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tbool\tbool\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\n",
      "VII_PIT1_2022\t9\tdatetime64[ns]\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tobject\tobject\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tobject\n",
      "VII_PIT2_2022\t10\tdatetime64[ns]\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tbool\tbool\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tobject\n",
      "VII_PIT3_2022\t11\tdatetime64[ns]\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tobject\tbool\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tobject\n",
      "VII_PIT4_2022\t12\tdatetime64[ns]\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tbool\tbool\tint64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tfloat64\tobject\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "print('\\t\\t\\t'+'1\\t\\t'+'\\t'.join(str(a) for a in [*range(2,49)]))\n",
    "for t1 in zip([*raw_data.items(), *clean_data.items()]):\n",
    "    print(f'{t1[0][0]}\\t{i}\\t'+'\\t'.join(str(x) for x in t1[0][1].dtypes.array))\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89496cb7",
   "metadata": {},
   "source": [
    "### Combine all raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41b712dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.DataFrame()\n",
    "for r in raw_data.values():\n",
    "    raw = pd.concat([raw, r])\n",
    "\n",
    "training_folder_path = f'{data_folder}/Training/'\n",
    "raw.to_csv(f'{training_folder_path}Raw_training_data_full.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
