{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "689fda5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "import math\n",
    "\n",
    "data_folder = \"../Data/\" #add your own folder name where the csv files are located"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11750d9c",
   "metadata": {},
   "source": [
    "### General variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6f440c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../Data/'\n",
    "print_text_result = False\n",
    "raw_data_names = ['pit1_data-2022', 'pit2_data-2022', 'pit3_data-2022', 'pit4_data-2022',\n",
    "                  'pit1_data-2023', 'pit2_data-2023', 'pit3_data-2023', 'pit4_data-2023']\n",
    "clean_data_names = ['VII_PIT1_2022', 'VII_PIT2_2022', 'VII_PIT3_2022', 'VII_PIT4_2022']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19558cda",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a471267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pit_suffix(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove suffix '_pit<number>' from header\n",
    "    \"\"\"\n",
    "    re_match = re.search(r'_pit\\d+$', name)\n",
    "    if re_match:\n",
    "        name = name[:re_match.start()]\n",
    "\n",
    "    return name\n",
    "\n",
    "def get_mixed_year_dates(df: pd.DataFrame, file_name: str, findings_dict: dict) -> int:\n",
    "    header = f'{file_name} year not matching'\n",
    "    start_date_2022 = datetime(2022, 1,1, 0, 0, 0)\n",
    "    start_date_2023 = datetime(2023, 1,1, 0, 0, 0)\n",
    "    start_date_2024 = datetime(2024, 1,1, 0, 0, 0)\n",
    "\n",
    "    if '2022' in file_name:\n",
    "        findings_dict[header] = (df.loc[(df['TIMESTAMP'] >= start_date_2023) | (df['TIMESTAMP'] < start_date_2022)].index.values + 2)\n",
    "    else:\n",
    "        findings_dict[header] = (df.loc[(df['TIMESTAMP'] >= start_date_2024) | (df['TIMESTAMP'] < start_date_2023)].index.values + 2 )\n",
    "\n",
    "    return len(findings_dict[header])\n",
    "\n",
    "\n",
    "def get_duplicate_dates(df: pd.DataFrame, file_name: str, findings_dict: dict) -> pd.DataFrame:\n",
    "    header = f'{file_name} duplicate date'\n",
    "    findings_dict[header] = (df[df['TIMESTAMP'].duplicated() == True].index.values + 2)\n",
    "\n",
    "    return len(findings_dict[header])\n",
    "\n",
    "def get_missing_values(df: pd.DataFrame, file_name: str, findings_dict: dict) -> pd.DataFrame:\n",
    "    header = f'{file_name} missing values'\n",
    "    findings_dict[header] = df[df.isnull().any(axis=1)].index.values + 2\n",
    "    header2 = f'{file_name} missing values col name'\n",
    "    findings_dict[header2] = df.columns[df.isnull().any()].tolist()\n",
    "\n",
    "    return len(findings_dict[header])\n",
    "\n",
    "def get_findings(df: pd.DataFrame, file_name: str, findings_dict: dict) -> dict:\n",
    "    diff_dict = dict()\n",
    "    diff_dict['Date_no_match'] = get_mixed_year_dates(df, file_name, findings_dict)\n",
    "    diff_dict['Duplicates'] = get_duplicate_dates(df, file_name, findings_dict)\n",
    "    diff_dict['NaNs'] = get_missing_values(df, file_name, findings_dict)\n",
    "\n",
    "    return diff_dict\n",
    "\n",
    "def load_data(file_names: list[str], data_folder: str, findings_dict: dict) -> dict:\n",
    "    dfs = dict()\n",
    "    \n",
    "    report_df = pd.DataFrame()\n",
    "\n",
    "    for file_name in file_names:\n",
    "        df = pd.read_csv(data_folder+file_name+'.csv', parse_dates=['TIMESTAMP'])\n",
    "        df.rename(mapper=remove_pit_suffix, axis='columns', inplace=True)\n",
    "\n",
    "        stats = get_findings(df, file_name, findings_dict)\n",
    "        report_df = pd.concat([report_df, pd.DataFrame(stats, index=[file_name])])\n",
    "        dfs[file_name] = df\n",
    "\n",
    "    report_df = report_df.assign(Total = lambda x: (x.sum(axis=1)))\n",
    "    report_df['row_cnt'] = [len(df) for df in dfs.values()]\n",
    "    print(report_df)\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce5bcde",
   "metadata": {},
   "source": [
    "### Load data and get findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "425335a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_129241/3030246735.py:2: DtypeWarning: Columns (34,37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = load_data(raw_data_names, data_folder, findings_dict)\n",
      "/tmp/ipykernel_129241/3030246735.py:2: DtypeWarning: Columns (34) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = load_data(raw_data_names, data_folder, findings_dict)\n",
      "/tmp/ipykernel_129241/3030246735.py:2: DtypeWarning: Columns (37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = load_data(raw_data_names, data_folder, findings_dict)\n",
      "/tmp/ipykernel_129241/3030246735.py:2: DtypeWarning: Columns (7,8,9,34,37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = load_data(raw_data_names, data_folder, findings_dict)\n",
      "/tmp/ipykernel_129241/3030246735.py:2: DtypeWarning: Columns (19,20,21,30,31,34,37,38) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = load_data(raw_data_names, data_folder, findings_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Date_no_match  Duplicates  NaNs  Total  row_cnt\n",
      "pit1_data-2022              1          12   267    280    75649\n",
      "pit2_data-2022              1          24  4348   4373    75949\n",
      "pit3_data-2022              1          12   167    180    27096\n",
      "pit4_data-2022              1          12   125    138    27264\n",
      "pit1_data-2023            287          15   279    581   104918\n",
      "pit2_data-2023           3250       25839  7215  36304   133640\n",
      "pit3_data-2023           1154          88   279   1521   106361\n",
      "pit4_data-2023            290         196  1143   1629   105594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_129241/3030246735.py:3: DtypeWarning: Columns (37,38,47) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  clean_data = load_data(clean_data_names, data_folder, findings_dict)\n",
      "/tmp/ipykernel_129241/3030246735.py:3: DtypeWarning: Columns (47) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  clean_data = load_data(clean_data_names, data_folder, findings_dict)\n",
      "/tmp/ipykernel_129241/3030246735.py:3: DtypeWarning: Columns (37,47) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  clean_data = load_data(clean_data_names, data_folder, findings_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Date_no_match  Duplicates   NaNs  Total  row_cnt\n",
      "VII_PIT1_2022              1         192  76117  76310    76117\n",
      "VII_PIT2_2022              1          24  72388  72413    75949\n",
      "VII_PIT3_2022              1          12  27094  27107    27096\n",
      "VII_PIT4_2022              1          12  25225  25238    25225\n"
     ]
    }
   ],
   "source": [
    "findings_dict = dict()\n",
    "raw_data = load_data(raw_data_names, data_folder, findings_dict)\n",
    "clean_data = load_data(clean_data_names, data_folder, findings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f22cbc",
   "metadata": {},
   "source": [
    "### Save findings as a csv\n",
    "\n",
    "Each column values are row index in the original csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "104cef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "findigs_df = pd.DataFrame.from_dict(dict([ (k,pd.Series(v)) for k,v in findings_dict.items() ]))\n",
    "findigs_df.to_csv('Data_date_missmatch_duplicate_rows_and_null_values.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd17ef9f",
   "metadata": {},
   "source": [
    "### Check where redox values differ in raw and cleaned data and save as csv\n",
    "\n",
    "Csv contains timestamp and redox values from both raw and cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "473be023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_129241/302096813.py:2: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  mm_values = pd.Series()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing pit1_data-2022  vs  VII_PIT1_2022\n",
      "\tNO MISSMATCH\n",
      "Comparing pit2_data-2022  vs  VII_PIT2_2022\n",
      "\tNO MISSMATCH\n",
      "Comparing pit3_data-2022  vs  VII_PIT3_2022\n",
      "\tFound 26533 missmatch with redox values\n",
      "Comparing pit4_data-2022  vs  VII_PIT4_2022\n",
      "\tNO MISSMATCH\n"
     ]
    }
   ],
   "source": [
    "# looping through 2022 data\n",
    "mm_values = pd.Series()\n",
    "for (raw_name, raw_df), (clean_name, clean_df) in zip(raw_data.items(), clean_data.items()):\n",
    "    print('Comparing', raw_name, ' vs ', clean_name)\n",
    "    \n",
    "    cols = ['TIMESTAMP', 'Redox_Avg(1)', 'Redox_Avg(2)', 'Redox_Avg(3)', 'Redox_Avg(4)', 'Redox_Avg(5)']\n",
    "    raw_compare = raw_df[cols]\n",
    "    clean_compare = clean_df[cols]\n",
    "\n",
    "    # merge Dataframes by matching TIMESTAMP\n",
    "    merged_df = raw_compare.merge(clean_compare, how='inner', on=['TIMESTAMP'], suffixes=('_raw', '_clean'))\n",
    "\n",
    "    matching_values = merged_df.apply(lambda x: True if (math.isnan(x['Redox_Avg(1)_clean']) or math.isclose(x['Redox_Avg(1)_raw'], x['Redox_Avg(1)_clean'], rel_tol=1e-3)) and\n",
    "                                                        (math.isnan(x['Redox_Avg(2)_clean']) or math.isclose(x['Redox_Avg(2)_raw'], x['Redox_Avg(2)_clean'], rel_tol=1e-3)) and\n",
    "                                                        (math.isnan(x['Redox_Avg(3)_clean']) or math.isclose(x['Redox_Avg(3)_raw'], x['Redox_Avg(3)_clean'], rel_tol=1e-3)) and\n",
    "                                                        (math.isnan(x['Redox_Avg(4)_clean']) or math.isclose(x['Redox_Avg(4)_raw'], x['Redox_Avg(4)_clean'], rel_tol=1e-3)) and\n",
    "                                                        (math.isnan(x['Redox_Avg(5)_clean']) or math.isclose(x['Redox_Avg(5)_raw'], x['Redox_Avg(5)_clean'], rel_tol=1e-3)) else False, axis=1)\n",
    "    \n",
    "    # Uncomment to check for larger gaps between the raw and clean values\n",
    "    # matching_values = merged_df.apply(lambda x: True if (math.isnan(x['Redox_Avg(1)_clean']) or abs(x['Redox_Avg(1)_raw'] - x['Redox_Avg(1)_clean']) <= 10) and\n",
    "    #                                                     (math.isnan(x['Redox_Avg(2)_clean']) or abs(x['Redox_Avg(2)_raw'] - x['Redox_Avg(2)_clean']) <= 10) and\n",
    "    #                                                     (math.isnan(x['Redox_Avg(3)_clean']) or abs(x['Redox_Avg(3)_raw'] - x['Redox_Avg(3)_clean']) <= 10) and\n",
    "    #                                                     (math.isnan(x['Redox_Avg(4)_clean']) or abs(x['Redox_Avg(4)_raw'] - x['Redox_Avg(4)_clean']) <= 10) and\n",
    "    #                                                     (math.isnan(x['Redox_Avg(5)_clean']) or abs(x['Redox_Avg(5)_raw'] - x['Redox_Avg(5)_clean']) <= 10) else False, axis=1)\n",
    "    \n",
    "    if len(matching_values[matching_values == False]) > 0:\n",
    "        print(f'\\tFound {len(merged_df[matching_values == False])} missmatch with redox values')\n",
    "        mm_values = matching_values.copy()\n",
    "        merged_df[matching_values == False].to_csv(f'Redox_value_not_same_{raw_name}_vs_{clean_name}')\n",
    "    else:\n",
    "        print('\\tNO MISSMATCH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffa0627",
   "metadata": {},
   "source": [
    "### Check if missmatch values are from another pit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b81b1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing pit3_data-2022  vs  VII_PIT1_2022\n",
      "\tNO MATCH\n",
      "Comparing pit3_data-2022  vs  VII_PIT2_2022\n",
      "\tNO MATCH\n",
      "Comparing pit3_data-2022  vs  VII_PIT3_2022\n",
      "\tNO MATCH\n",
      "Comparing pit3_data-2022  vs  VII_PIT4_2022\n",
      "\tNO MATCH\n"
     ]
    }
   ],
   "source": [
    "mm_data_name = 'pit3_data-2022'\n",
    "mm_df = raw_data[mm_data_name].iloc[mm_values[mm_values == False].index.values]\n",
    "\n",
    "for clean_name, clean_df in clean_data.items():\n",
    "    print('Comparing', mm_data_name, ' vs ', clean_name)\n",
    "\n",
    "    cols = ['TIMESTAMP', 'Redox_Avg(1)', 'Redox_Avg(2)', 'Redox_Avg(3)', 'Redox_Avg(4)', 'Redox_Avg(5)']\n",
    "    raw_compare = mm_df[cols]\n",
    "    clean_compare = clean_df[cols]\n",
    "\n",
    "    # merge Dataframes by matching TIMESTAMP\n",
    "    merged_df = raw_compare.merge(clean_compare, how='inner', on=['TIMESTAMP'], suffixes=('_raw', '_clean'))\n",
    "\n",
    "    # matching_values = merged_df.apply(lambda x: True if (math.isnan(x['Redox_Avg(1)_clean']) or math.isclose(x['Redox_Avg(1)_raw'], x['Redox_Avg(1)_clean'], rel_tol=1e-3)) and\n",
    "    #                                                     (math.isnan(x['Redox_Avg(2)_clean']) or math.isclose(x['Redox_Avg(2)_raw'], x['Redox_Avg(2)_clean'], rel_tol=1e-3)) and\n",
    "    #                                                     (math.isnan(x['Redox_Avg(3)_clean']) or math.isclose(x['Redox_Avg(3)_raw'], x['Redox_Avg(3)_clean'], rel_tol=1e-3)) and\n",
    "    #                                                     (math.isnan(x['Redox_Avg(4)_clean']) or math.isclose(x['Redox_Avg(4)_raw'], x['Redox_Avg(4)_clean'], rel_tol=1e-3)) and\n",
    "    #                                                     (math.isnan(x['Redox_Avg(5)_clean']) or math.isclose(x['Redox_Avg(5)_raw'], x['Redox_Avg(5)_clean'], rel_tol=1e-3)) else False, axis=1)\n",
    "    # Uncomment to check for larger gaps between the raw and clean values\n",
    "    matching_values = merged_df.apply(lambda x: True if (math.isnan(x['Redox_Avg(1)_clean']) or abs(x['Redox_Avg(1)_raw'] - x['Redox_Avg(1)_clean']) <= 50) and\n",
    "                                                        (math.isnan(x['Redox_Avg(2)_clean']) or abs(x['Redox_Avg(2)_raw'] - x['Redox_Avg(2)_clean']) <= 50) and\n",
    "                                                        (math.isnan(x['Redox_Avg(3)_clean']) or abs(x['Redox_Avg(3)_raw'] - x['Redox_Avg(3)_clean']) <= 50) and\n",
    "                                                        (math.isnan(x['Redox_Avg(4)_clean']) or abs(x['Redox_Avg(4)_raw'] - x['Redox_Avg(4)_clean']) <= 50) and\n",
    "                                                        (math.isnan(x['Redox_Avg(5)_clean']) or abs(x['Redox_Avg(5)_raw'] - x['Redox_Avg(5)_clean']) <= 50) else False, axis=1)\n",
    "\n",
    "    if len(matching_values[matching_values == False]) > 0:\n",
    "        print(f'\\tNO MATCH')\n",
    "    else:\n",
    "        print(f'\\tData is from pit {clean_name}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63879d78",
   "metadata": {},
   "source": [
    "### See if raw data has missing values on timestamps where clean data has redox error flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3abf24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing pit1_data-2022  vs  VII_PIT1_2022\n",
      "\tNO MISSING VALUES FOR REDOX ERROR\n",
      "Comparing pit2_data-2022  vs  VII_PIT2_2022\n",
      "\tColumns with missing values Redox_Avg(2) ,Redox_Avg(3) ,Redox_Avg(4) ,Redox_Avg(5)\n",
      "\tTotal rows 2\n",
      "\tRow index 60556 ,60557\n",
      "\tRaw data:\n",
      "       Redox_Avg(1)  Redox_Avg(2)  Redox_Avg(3)  Redox_Avg(4)  Redox_Avg(5)\n",
      "60554        223.89           NaN           NaN           NaN           NaN\n",
      "60555       1023.00           NaN           NaN           NaN           NaN\n",
      "\tClean data:\n",
      "       Redox_Avg(1)  Redox_Avg(2)  Redox_Avg(3)  Redox_Avg(4)  Redox_Avg(5)\n",
      "60554           NaN           NaN           NaN           NaN           NaN\n",
      "60555           NaN           NaN           NaN           NaN           NaN\n",
      "Comparing pit3_data-2022  vs  VII_PIT3_2022\n",
      "\tNO MISSING VALUES FOR REDOX ERROR\n",
      "Comparing pit4_data-2022  vs  VII_PIT4_2022\n",
      "\tNO MISSING VALUES FOR REDOX ERROR\n"
     ]
    }
   ],
   "source": [
    "# looping through 2022 data\n",
    "for (raw_name, raw_df), (clean_name, clean_df) in zip(raw_data.items(), clean_data.items()):\n",
    "    print('Comparing', raw_name, ' vs ', clean_name)\n",
    "\n",
    "    error_flags_index = clean_df[clean_df['Redox_error_flag'] == True].index\n",
    "    raw_data_points_with_error_flag = raw_df.iloc[error_flags_index]\n",
    "    raw_data_missing_values = raw_data_points_with_error_flag[raw_data_points_with_error_flag.isnull().any(axis=1)]\n",
    "\n",
    "    if len(raw_data_missing_values) > 0:\n",
    "        cols_with_missing_data = raw_data_missing_values.columns[raw_data_missing_values.isnull().any()].tolist()\n",
    "        cols = ' ,'.join(cols_with_missing_data)\n",
    "        print(f'\\tColumns with missing values {cols}')\n",
    "        print(f'\\tTotal rows {len(raw_data_missing_values)}')\n",
    "        rows_index = ' ,'.join(map(str, raw_data_missing_values.index.values+2))\n",
    "        print(f'\\tRow index {rows_index}')\n",
    "        print('\\tRaw data:')\n",
    "        vals = raw_data_missing_values[['Redox_Avg(1)', *cols_with_missing_data]]\n",
    "        print(f'{vals}')\n",
    "        print('\\tClean data:')\n",
    "        vals = clean_df[['Redox_Avg(1)', *cols_with_missing_data]].iloc[raw_data_missing_values.index.values]\n",
    "        print(f'{vals}')\n",
    "    else:\n",
    "        print('\\tNO MISSING VALUES FOR REDOX ERROR')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798e5d44",
   "metadata": {},
   "source": [
    "### Get values according to findigs csv rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8d5d669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = 11559 - 2 \n",
    "# end = 11582 - 1\n",
    "# pit = 'VII_PIT4_2022'\n",
    "# clean_data[pit][clean_data[pit]['TIMESTAMP'].duplicated() == True]\n",
    "# clean_data[pit]['TIMESTAMP'].iloc[start:end]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
